<center>
<img src="https://i.zeyu.tw/blog/assets/zeyu.jpg" width="150px"/>
<h1 id="zeyu-zhang">张泽宇</h1>
<p><strong>E-mail: <a href="mailto:zeyu.damien.zhang@gmail.com">zeyu.damien.zhang@gmail.com</a> | +8617689468368</strong></p>
</center>
<hr>
<h2 id="education">教育背景</h2>
<ul>
<li><strong>上海交通大学</strong> (2017年09月-2020年06月)<ul>
<li>软件工程硕士学位</li>
</ul>
</li>
<li><strong>武汉大学</strong> (2013年09月-2017年06月)<ul>
<li>软件工程学士学位</li>
</ul>
</li>
</ul>
<h2 id="research-interests">科研兴趣</h2>
<ul>
<li><strong>主研究领域:</strong> 基于思科高性能包处理框架VPP(向量包处理)的用户态网络协议栈研究</li>
<li><strong>本科时研究领域:</strong> 适用于轨迹预测的推荐算法系统</li>
<li><strong>相关兴趣领域:</strong> 网络系统管理与优化 | 虚拟化 | 推荐系统</li>
</ul>
<h2 id="research-experience--achievements">研究经历与成果</h2>
<p><strong><em>基于思科高性能包处理框架VPP(向量包处理)的用户态网络协议栈优化,</em></strong> 上海交通大学 &amp; 英特尔</p>
<p><strong>2018年08月-2020年02月</strong></p>
<p><strong>实验室:</strong></p>
<ul>
<li><strong>SDIC Group</strong> (Software-Defined Infrastructure for Cloud Group, 上海交通大学) [<a href="http://sdic.sjtu.edu.cn/" target="_blank">网站</a>]</li>
<li><strong>NCLG</strong> (Network and Custom Logic Group, 英特尔)</li>
</ul>
<p><strong>导师:</strong></p>
<ul>
<li><strong>李健</strong>副教授 (上海交通大学) (<a href="mailto:&#x6c;&#105;&#45;&#106;&#x69;&#97;&#110;&#x40;&#115;&#106;&#116;&#x75;&#46;&#101;&#100;&#117;&#x2e;&#99;&#x6e;">&#x6c;&#105;&#45;&#106;&#x69;&#97;&#110;&#x40;&#115;&#106;&#116;&#x75;&#46;&#101;&#100;&#117;&#x2e;&#99;&#x6e;</a>) [<a href="http://sdic.sjtu.edu.cn/index.php/jian-li/" target="_blank">网站</a>]</li>
<li><strong>虞平</strong> (英特尔) (<a href="mailto:&#x70;&#x69;&#x6e;&#103;&#x2e;&#x79;&#117;&#64;&#105;&#110;&#x74;&#x65;&#108;&#46;&#x63;&#x6f;&#x6d;">&#x70;&#x69;&#x6e;&#103;&#x2e;&#x79;&#117;&#64;&#105;&#110;&#x74;&#x65;&#108;&#46;&#x63;&#x6f;&#x6d;</a>)</li>
<li><strong>Florin Coras</strong> (VPP 技术主管, 思科) (<a href="mailto:&#102;&#x63;&#111;&#x72;&#x61;&#115;&#64;&#99;&#105;&#115;&#99;&#111;&#x2e;&#x63;&#111;&#109;">&#102;&#x63;&#111;&#x72;&#x61;&#115;&#64;&#99;&#105;&#115;&#99;&#111;&#x2e;&#x63;&#111;&#109;</a>)</li>
<li><strong>管海兵</strong>教授 (上海交通大学) (<a href="mailto:&#104;&#x62;&#103;&#x75;&#97;&#110;&#x40;&#x73;&#106;&#x74;&#117;&#x2e;&#101;&#100;&#117;&#x2e;&#99;&#x6e;">&#104;&#x62;&#103;&#x75;&#97;&#110;&#x40;&#x73;&#106;&#x74;&#117;&#x2e;&#101;&#100;&#117;&#x2e;&#99;&#x6e;</a>) [<a href="http://www.cs.sjtu.edu.cn/~hbguan/" target="_blank">网站</a>]</li>
</ul>
<p><strong>我的研究主题:</strong> 基于VPP对NGINX进行优化以提升吞吐量，实现良好的可扩展性，减少延迟，以及减少CPU占用率。</p>
<p><strong>什么是FD.io VPP (摘自个人论文):</strong></p>
<ul><li>
<details>
<summary style="color:#0000FF"><i>点击此处查看更多</i></summary>
<p>FD.io VPP (Vector Packet Processing), adopting the novel application-networking-separated process model, is a high-performance user-space packet processing framework built on DPDK, providing a full L2-L7 user-space networking stack. FD.io VPP leverages Vector Packet Processing to process a batch of packets at a time through a set of pluggable graph function nodes, with the goal of optimizing i-cache and d-cache locality. The networking functionality of FD.io VPP is put into an ordinary Linux user-space process. Multiple network applications can use VPP LDP API without modifying source code to utilize the networking functionality provided by VPP process at the same time over user-space lock-free shared memory queues. Such approach decouples the release of new networking functionality from both kernel and application binary release cycles and decouples application threading and CPU provisioning from network service.</p>
<p>Moreover, at VPP process side, the packet processing pipeline in VPP can be organized as a packet processing graph. Each graph node in the graph acts as a graph function node that performs a speciﬁc packet processing task. Anyone can add custom graph function nodes into the packet processing graph to perform speciﬁc customized tasks on demand, enabling VPP to be extensible. Alongside the packet processing graph nodes, a batch of packets assembled from RX rings are processed together, with the aim of optimizing i-cache and d-cache locality. Such modular design makes it easy for developers to upgrade networking functionality in VPP networking stack.</p>
</details>
</li></ul>
<p><strong>个人经历:</strong></p>
<ul><li>
<details>
<summary style="color:#0000FF"><i>点击此处查看更多</i></summary>
<p>在所有研究生课程结束后，我于2018年夏季加入了这个项目。在该项目的上半年，我在SDIC做研究，与英特尔上海分公司的技术负责人虞平合作。我的工作是评估VPP用户态网络协议栈的性能。因此，我选择了NGINX来进行此实验。但是实验结果比我将VPP集成到NGINX中时的预期要差。与原生NGINX相比，糟糕的可扩展性，满负荷CPU占用率，和更高的请求延迟都出现在我眼前。因此，自那时以来，我的主要工作是寻找原因并解决这些问题。在那段时间里，我常常与虞平还有思科VPP技术负责人Florin Coras进行了交谈，讨论我发现有哪些干扰VPP性能的问题。随着工作的持续进行，我于​​2019年6月3日开始在英特尔实习，并于12月完成了我的所有工作。</p>
</details>
</li></ul>
<p><strong>我的成果:</strong></p>
<ul>
<li><strong>VPPNGX：基于FD.io VPP的高性能NGINX实现,</strong> 包含以下成果:<ul>
<li><strong>VPP会话索引透传机制:</strong> 使用VPP Session Index Passthrough（VPP会话索引透传机制）将FD.io VPP的Session Lock Layer（会话锁层）安全删除。Session Lock Layer对VPPNGX的可扩展性有负面影响，并且还增加了网络包处理的延迟。</li>
<li><strong>基于令牌的无锁化保序机制:</strong> 当FD.io VPP的Session Lock Layer被去除后，从NGINX发向VPP的控制事件消息在入队VPP Event Queue（VPP事件队列）时它们的元数据可能会发生乱序。我为VPP Event Queue设计了一个Token-Based Lock-Free Order-Preserving Approach（基于令牌的无锁化保序机制）以在去除Session Lock Layer后，在不重新引入巨锁的情况下保证控制事件消息在入队VPP Event Queue时它们的元数据不会发生乱序。</li>
<li><strong>用户态联合阻塞式epoll机制:</strong> 在NGINX端，NGINX使用Busy-Wait Polling epoll（忙等轮询式epoll机制）去同时检查用户态的会话epoll事件和内核态的epoll事件。Busy-Wait Polling epoll会导致NGINX的所有工作进程无论是否有网络请求处理均始终百分之百地占用 CPU，并且还会增加上下文切换的开销（陷入内核检查内核epoll事件）。我设计了User-Space Unified Blocking epoll（用户态联合阻塞式epoll机制）去替换Busy-Wait Polling epoll，以实现阻塞功能减少CPU占用率，并减少进行内核epoll事件检查引起的上下文切换开销。
</li>
<li><strong>实验结果:</strong> VPPNGX在RPS（Requests per Second，请求数/秒）方面达到了基于内核的NGINX的3.33倍。并且相比于直接使用VPP的NGINX，VPPNGX在RPS方面有很好的可扩展性。而且VPPNGX的RPS还比直接使用VPP的NGINX的更高。VPPNGX的请求处理延迟比F-Stack NGINX、直接使用VPP的NGINX、基于内核的NGINX要分别低46.7%、34.1%、25.3%。得益于User-Space Unified Blocking epoll（用户态联合阻塞式epoll机制），VPPNGX能够在网络请求负载较小的时候减少CPU的使用率，并且减少因内核epoll事件检查而造成的上下文切换开销。</li>
</ul>
</li>
</ul>
<hr>
<p><strong><em>移动消费群组识别项目,</em></strong> 武汉大学</p>
<p><strong>2016年03月-2017年07月</strong></p>
<p><strong>实验室:</strong></p>
<ul>
<li>BDCC Lab (Big Data and Cloud Computing Lab, 武汉大学) [<a href="http://bdcclab.com/index_en.htm" target="_blank">网站</a>]</li>
</ul>
<p><strong>导师:</strong></p>
<ul>
<li><strong>崔晓辉</strong>教授 (武汉大学) (<a href="mailto:&#x78;&#x63;&#117;&#x69;&#x40;&#x77;&#104;&#x75;&#x2e;&#101;&#x64;&#x75;&#46;&#99;&#110;">&#x78;&#x63;&#117;&#x69;&#x40;&#x77;&#104;&#x75;&#x2e;&#101;&#x64;&#x75;&#46;&#99;&#110;</a>) [<a href="https://www.researchgate.net/profile/Xiaohui_Cui3" target="_blank">网站</a>]</li>
<li><strong>朱卫平</strong>副教授 (武汉大学) (<a href="mailto:&#x77;&#112;&#x7a;&#x68;&#x75;&#64;&#119;&#104;&#117;&#46;&#101;&#x64;&#x75;&#46;&#x63;&#110;">&#x77;&#112;&#x7a;&#x68;&#x75;&#64;&#119;&#104;&#117;&#46;&#101;&#x64;&#x75;&#46;&#x63;&#110;</a>) [<a href="http://bdcclab.com/wpzhu/en.htm" target="_blank">网站</a>]</li>
</ul>
<p><strong>小组研究主题:</strong> 使用Android手机上的运动传感器和室内Wi-Fi定位，准确识别购物中心的消费群组。通过预测消费者群组的群体行为来实现商场商家的利润最大化。</p>
<p><strong>个人贡献:</strong></p>
<ul>
<li>负责收集和分析Wi-Fi和运动数据，然后跟踪和预测消费者的室内移动轨迹。</li>
<li>设计了一种改进的Apriori算法，该算法能够有效地进行轨迹预测，从而获得消费者在大型购物中心未来所处位置的概率。</li>
<li><strong>以一作身份发表了论文“Location and Motion Prediction of Consumers in a Large Shopping Mall”。可以在下面的“已发表论文”中查看更多有关该论文的信息。</strong></li>
</ul>
<h2 id="publication">已发表论文</h2>
<p><strong>Zhang, Zeyu</strong>, and Weiping Zhu. &quot;Location and Motion Prediction of Consumers in a Large Shopping Mall.&quot; In 2017 Fifth International Conference on Advanced Cloud and Big Data (CBD), pp. 250-255. IEEE, 2017. [<a href="http://bdcclab.com/wpzhu/fundation/LocationMotionPredictionConsumersInShoppingMall1-3.pdf" target="_blank">PDF</a>]</p>
<h2 id="patent">专利</h2>
<p>一种网络请求处理系统和方法 (李健, <strong>张泽宇</strong>, 管海兵) (专利号: 202010059255.0)</p>
<h2 id="internship-experience">实习经历</h2>
<p>英特尔, 上海 (Linux软件开发) === 2019年06月03日-2019年10月31日</p>
<h2 id="honors-and-awards">各类荣誉证书</h2>
<ul>
<li>优秀毕业生, 上海交通大学, 2020年06月</li>
<li>优秀党员, 上海交通大学电院, 2018年12月</li>
<li>三好学生, 上海交通大学, 2018年10月</li>
<li>优秀学生, 武汉大学, 2016年12月</li>
<li>优秀学生, 武汉大学, 2015年12月</li>
<li>学生社团活动积极分子, 武汉大学, 2015年04月</li>
<li>暑期社会实践活动先进个人, 武汉大学, 2015年01月</li>
<li>优秀学生, 武汉大学, 2014年12月</li>
</ul>
